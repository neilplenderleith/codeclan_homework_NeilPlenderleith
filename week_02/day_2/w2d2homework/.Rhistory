.after = display_text_width)
tweets %>%
mutate(text_width = nchar(text, type = "width"),
.after = display_text_width)
tweets %>%
mutate(text_width = str_length(text),
.after = display_text_width)
tweets %>%
mutate(text_width = str_length(text),
.after = display_text_width)
summarise(mean_characters = mean(nchar(text)))
summarise(mean_characters = mean(text_width))
tweets %>%
mutate(text_width = str_length(text),
.after = display_text_width)
summarise(mean_characters = mean(text_width))
tweets %>%
mutate(text_width = str_length(text),
.after = display_text_width) %>%
summarise(mean_characters = mean(text_width))
tweets %>%
summarise(mean_characters = mean(display_text_width))
tweet_count <- tweets %>%
mutate(text_width = str_length(text),
.after = display_text_width) %>%
summarise(mean_characters = mean(text_width))
View(tweet_count)
tweet_count <- tweets %>%
mutate(text_width = str_length(text),
.after = display_text_width)
View(tweet_count)
tweet_count <- tweets %>%
mutate(text_width = str_length(text),
.after = display_text_width) %>%
summarise(mean_characters = mean(text_width))
tweets %>%
mutate(text_width = str_length(text),
.after = display_text_width) %>%
summarise(mean_characters = mean(text_width))
info <- read_csv("data/code_clan_info.csv")
View(info)
tweet_info <- left_join(tweets, info, by = "tweet_id")
View(tweets)
View(tweet_info)
tweet_info %>%
filter(!is_empty(hashtags))
tweet_info %>%
drop_na(hashtags)
hashtags <- tweet_info %>%
drop_na(hashtags) %>%
select(tweet_id, hashtags) %>%
mutate(hashtages = str_to_lower(hashtags))
hashtags
hashtags <- tweet_info %>%
drop_na(hashtags) %>%
select(tweet_id, hashtags) %>%
mutate(hashtages = str_to_lower(hashtags))
hashtags
hashtags <- tweet_info %>%
drop_na(hashtags) %>%
select(tweet_id, hashtags) %>%
mutate(hashtags = str_to_lower(hashtags))
hashtags
hashtags <- tweet_info %>%
drop_na(hashtags) %>%
select(tweet_id, hashtags) %>%
mutate(hashtags = str_to_lower(hashtags))
hashtags
codeclan_hashtags <- tweet_info %>%
drop_na(hashtags) %>%
select(tweet_id, hashtags) %>%
mutate(hashtags = str_to_lower(hashtags))
hashtags
codeclan_hashtags %>%
head(n=1)
codeclan_hashtags %>%
head(n=1) %>%
str_sub (hashtags)
codeclan_hashtags %>%
head(n=1) %>%
str_sub(hashtags, 1, 6)
codeclan_hashtags %>%
head(n=1) %>%
str_sub(hashtags, 1, 3)
codeclan_hashtags %>%
head(n=1)
codeclan_hashtags %>%
head(n=1) %>%
str_sub(hashtags, 1, 2)
codeclan_hashtags %>%
head(n=1) %>%
str_sub(hashtags, 1)
codeclan_hashtags %>%
head(n=1) %>%
str_sub(tweet_id, 1, 3)
str_sub("tweet_id", 1, 3)
codeclan_hashtags %>%
mutate(multiple_hashtags = if_else((str_sub(hashtags 1, 2)) == "c(", TRUE, FALSE))
codeclan_hashtags %>%
mutate(multiple_hashtags = if_else((str_sub(hashtags, 1, 2)) == "c(", TRUE, FALSE))
codeclan_hashtags %>%
mutate(multiple_hashtags = if_else((str_sub(hashtags, 1, 2)) == "c(", TRUE, FALSE)) %>%
filter(multiple_hashtags == TRUE)
codeclan_hashtags %>%
mutate(multiple_hashtags = if_else((str_sub(hashtags, 1, 2)) == "c(", TRUE, FALSE)) %>%
filter(multiple_hashtags == TRUE) %>%
select(tweet_id, hashtags)
filter(str_detect(hashtags, "^c\\(") == TRUE
codeclan_hashtags %>%
codeclan_hashtags %>%
filter((str_detect(hashtags, "^c\\(")) == TRUE)
codeclan_hashtags %>%
filter(if_else((str_sub(hashtags, 1, 2)) == "c(", TRUE, FALSE) == TRUE)
str_sub("c(lalalala)", 1, 2)
tweets %>%
# mutate(text = str_to_lower(text))
filter(str_detect(text, "(?i)edinburgh") == TRUE)
tweets %>%
# mutate(text = str_to_lower(text))
filter(str_detect(text, "(?i)edinburgh") == TRUE) %>%
summarise(n())
tweets %>%
# mutate(text = str_to_lower(text))
filter(str_detect(text, "(?i)edinburgh") == TRUE)
tweets %>%
# mutate(text = str_to_lower(text)) - Don't need this just use regex with (?i)
filter(str_detect(text, "(?i)edinburgh") == TRUE) %>%
summarise(n())
tweets %>%
pull(text)
tweets %>%
pull(text) %>%
str_detect("@")
tweets %>%
pull(text) %>%
count(str_detect("@"))
tweets %>%
pull(text) %>%
(str_detect("@"))
tweets %>%
pull(text) %>%
(str_count("@"))
tweets %>%
pull(text) %>%
str_count("@")
tweets %>%
pull(text) %>%
sum(str_count("@"))
tweets %>%
pull(text) %>%
(str_count("@"))
tweets %>%
pull(text) %>%
str_count("@")
tweets %>%
pull(text) %>%
str_detect("@")
tweets %>%
pull(text) %>%
str_extract_all("@[:punct:]*[a-zA-Z0-9]+")
tweets %>%
pull(text) %>%
str_extract_all("@[a-zA-Z0-9[:punct:]]+")
tweets %>%
pull(text)
tweets %>%
pull(text) %>%
str_extract_all("@[a-zA-Z0-9[:punct:]]+")
tweets %>%
pull(text)
tweets %>%
pull(text) %>%
str_extract_all("@[a-zA-Z0-9[:punct:]]+")
tweets %>%
pull(text)
tweets %>%
pull(text) %>%
str_extract_all("@[a-zA-Z0-9_]+")
tweets %>%
pull(text) %>%
str_extract_all("@[a-zA-Z0-9_]+") %>%
flatten_chr()
# try and check
tweets %>%
pull(text) %>%
string_extract_all("@")
# try and check
tweets %>%
pull(text) %>%
str_extract_all("@")
tweets %>%
pull(text) %>%
str_extract_all("@[a-zA-Z0-9_]+") %>%
flatten_chr() # finds 256 twitter names
# try and check
tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr()
# only punctuation allowed in a twitter name is an _ thanks google
tweets %>%
pull(text) %>%
str_extract_all("@[a-zA-Z0-9_]{1,15}") %>%
flatten_chr() # finds 256 twitter names
library(tidyverse)
tweets <- read_csv("data/code_clan_tweets.csv")
tweets
glimpse(tweets)
psych::describe(tweets)
skimr::skim(tweets)
tweets %>%
filter(is_quote == FALSE) %>%
summarise(sum(favorite_count))
tweets %>%
filter(is_quote == FALSE) %>%
group_by(source) %>%
summarise(mean_retweets = mean(retweet_count))
tweets %>%
count(media_type)
# there are 145 NAs lets change these to text?
tweets %>%
mutate(media_type = if_else(is.na(media_type), "text", media_type)) %>%
group_by(media_type) %>%
summarise(total_favourite_count = sum(favorite_count)) %>%
arrange(desc(total_favourite_count))
tweets %>%
mutate(text_width = str_length(text),
.after = display_text_width) %>%
summarise(mean_characters = mean(text_width))
# tweets %>%
#   summarise(mean_characters = mean(display_text_width))
# DISPLAY TEXT WIDTH IS LIES!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
info <- read_csv("data/code_clan_info.csv")
tweet_info <- left_join(tweets, info, by = "tweet_id")
codeclan_hashtags <- tweet_info %>%
drop_na(hashtags) %>%
select(tweet_id, hashtags) %>%
mutate(hashtags = str_to_lower(hashtags))
hashtags
colnames(tweets)
tweets %>%
filter(is_quote == FALSE) %>%
group_by(source) %>%
summarise(mean_retweets = round(mean(retweet_count)), 2)
tweets %>%
filter(is_quote == FALSE) %>%
group_by(source) %>%
summarise(mean_retweets = round(mean(retweet_count), 2))
tweets %>%
count(media_type)
tweets %>%
mutate(media_type = if_else(is.na(media_type), "text", media_type))
tweets %>%
mutate(media_type = if_else(is.na(media_type), "text", media_type)) %>%
group_by(media_type) %>%
summarise(total_favourite_count = sum(favorite_count)) %>%
arrange(desc(total_favourite_count))
tweet_info
info <- read_csv("data/code_clan_info.csv")
codeclan_hashtags <- tweet_info %>%
drop_na(hashtags) %>%
select(tweet_id, hashtags) %>%
mutate(hashtags = str_to_lower(hashtags))
hashtags
codeclan_hashtags
codeclan_hashtags <- tweet_info %>%
drop_na(hashtags) %>%
select(tweet_id, hashtags) %>%
mutate(hashtags = str_to_lower(hashtags))
codeclan_hashtags
# using str_detect
codeclan_hashtags %>%
filter((str_detect(hashtags, "^c\\(")) == TRUE)
# using str_sub
codeclan_hashtags %>%
filter(if_else((str_sub(hashtags, 1, 2)) == "c(", TRUE, FALSE) == TRUE)
tweets %>%
# mutate(text = str_to_lower(text)) - Don't need this just use regex with (?i)
filter(str_detect(text, "(?i)edinburgh") == TRUE)
tweets %>%
# mutate(text = str_to_lower(text)) - Don't need this just use regex with (?i)
filter(str_detect(text, "(?i)edinburgh") == TRUE) %>%
nrow()
# The only punctuation allowed in a twitter name is an _ thanks google
tweets %>%
pull(text) %>%
str_extract_all("@[a-zA-Z0-9_]+") %>%
flatten_chr() # finds 256 twitter names
# try and check we've found them all by counting just "@" symbols
tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr() # find 256 plus some erroneous entries we can ignore
count()
#Check we've found them all by counting just "@" symbols
tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr() %>% # find 256 plus some erroneous entries we can ignore
count()
#Check we've found them all by counting just "@" symbols
tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr() %>% # find 256 plus some erroneous entries we can ignore
str_count("@")
#Check we've found them all by counting just "@" symbols
tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr() %>% # find 256 plus some erroneous entries we can ignore
sum(str_count("@"))
#Check we've found them all by counting just "@" symbols
tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr() %>% # find 256 plus some erroneous entries we can ignore
count(str_count("@"))
#Check we've found them all by counting just "@" symbols
tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr() %>% # find 256 plus some erroneous entries we can ignore
str_length("@")
#Check we've found them all by counting just "@" symbols
tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr() %>% # find 256 plus some erroneous entries we can ignore
str_length()
tweets %>%
pull(text) %>%
str_extract_all("@")
tweets %>%
pull(text) %>%
str_count("@")
tweets %>%
pull(text) %>%
str_count("@") %>%
flatten_int()
tweets %>%
pull(text) %>%
str_count("@") %>%
flatten()
tweets %>%
pull(text) %>%
str_count("@") %>%
flatten_dbl()
tweets %>%
pull(text) %>%
str_count("@")
tweets %>%
pull(text) %>%
str_count("@") %>%
flatten_dbl()
tweets %>%
pull(text) %>%
str_count("@")
tweets %>%
pull(text) %>%
str_count("@") %>%
flatten_raw()
tweets %>%
pull(text) %>%
str_count("@") %>%
flatten_chr()
tweets %>%
pull(text) %>%
str_extract_all("@")
tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr()
#Check we've found them all by counting just "@" symbols
tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr() %>% # find 256 plus some erroneous entries we can ignore
str_c()
#Check we've found them all by counting just "@" symbols
tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr() %>% # find 256 plus some erroneous entries we can ignore
str_c(sep="")
#Check we've found them all by counting just "@" symbols
tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr() %>% # find 256 plus some erroneous entries we can ignore
str_c(sep = " ")
#Check we've found them all by counting just "@" symbols
tweet_check <- tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr()
tweet_check
# find 256 plus some erroneous entries we can ignore
str_c(tweet_check)
# find 256 plus some erroneous entries we can ignore
type(tweet_check)
# find 256 plus some erroneous entries we can ignore
value(tweet_check)
# find 256 plus some erroneous entries we can ignore
type(tweet_check)
# find 256 plus some erroneous entries we can ignore
typeof(tweet_check)
# find 256 plus some erroneous entries we can ignore
count(tweet_check)
# find 256 plus some erroneous entries we can ignore
unique(tweet_check)
# find 256 plus some erroneous entries we can ignore
coll(tweet_check)
# find 256 plus some erroneous entries we can ignore
nzchar(tweet_check)
# find 256 plus some erroneous entries we can ignore
count(nzchar(tweet_check))
# find 256 plus some erroneous entries we can ignore
sum(nzchar(tweet_check))
sum(tweet_check)
#Check we've found them all by counting just "@" symbols
tweet_check <- tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr() %>%
sum(nzchar(tweet_check))
#Check we've found them all by counting just "@" symbols
tweet_check <- tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr() %>%
sum(nzchar())
#Check we've found them all by counting just "@" symbols
tweet_check <- tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr() %>%
nzchar()
#Check we've found them all by counting just "@" symbols
tweet_check <- tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr() %>%
nzchar() %>%
sum()
#Check we've found them all by counting just "@" symbols
tweets %>%
pull(text) %>%
str_extract_all("@") %>%
flatten_chr() %>%
nzchar() %>%
sum()
# The only punctuation allowed in a twitter name is an _ thanks google
tweets %>%
pull(text) %>%
str_extract_all("@[a-zA-Z0-9_]+") %>%
flatten_chr() # finds 256 twitter names
library(tidyverse)
tweets <- read_csv("data/code_clan_tweets.csv")
tweets
glimpse(tweets)
psych::describe(tweets)
skimr::skim(tweets)
colnames(tweets) # lists the variable names as per the question
tweets %>%
filter(is_quote == FALSE) %>%
summarise(sum(favorite_count))
# 425 favourites
tweets %>%
filter(is_quote == FALSE) %>%
group_by(source) %>%
summarise(mean_retweets = round(mean(retweet_count), 2))
tweets %>%
count(media_type)
# there are 145 NAs lets change these to "text"?
tweets %>%
mutate(media_type = if_else(is.na(media_type), "text", media_type)) %>%
group_by(media_type) %>%
summarise(total_favourite_count = sum(favorite_count)) %>%
arrange(desc(total_favourite_count))
tweets %>%
mutate(text_width = str_length(text),
.after = display_text_width) %>%
summarise(mean_characters = mean(text_width))
# tweets %>%
#   summarise(mean_characters = mean(display_text_width))
# DISPLAY TEXT WIDTH IS LIES!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
info <- read_csv("data/code_clan_info.csv")
tweet_info <- left_join(tweets, info, by = "tweet_id")
codeclan_hashtags <- tweet_info %>%
drop_na(hashtags) %>%
select(tweet_id, hashtags) %>%
mutate(hashtags = str_to_lower(hashtags))
codeclan_hashtags
# using str_detect
codeclan_hashtags %>%
filter((str_detect(hashtags, "^c\\(")) == TRUE)
# using str_sub
codeclan_hashtags %>%
filter(if_else((str_sub(hashtags, 1, 2)) == "c(", TRUE, FALSE) == TRUE)
# I wasnt clear if this was to be 2 methods, i.e. 1 using each function or not
# Thats the way i've answered it anyway
tweets %>%
# mutate(text = str_to_lower(text)) - Don't need this just use regex with (?i)
filter(str_detect(text, "(?i)edinburgh") == TRUE) %>%
nrow()
# there are 33
tweet_info <- left_join(tweets, info, by = "tweet_id")
tweet_info <- left_join(tweets, info, by = "tweet_id")
tweet_info
tweet_info <- left_join(tweets, info, by = "tweet_id")
tweet_info
